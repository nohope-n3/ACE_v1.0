{"cells":[{"cell_type":"markdown","metadata":{"id":"0UKu9b7N6cPF"},"source":["# Bài thực hành số 3:  \n","\n","Chào mừng đến với bài thực hành số 3, trong bài thực hành này ta sẽ học cách áp dụng thuật toán Canny vào việc nhận diện làn đường cho xe tự lái."]},{"cell_type":"markdown","metadata":{"id":"Aw6SAiAP6gLh"},"source":["# Tổng quan\n","\n","Xe tự lái là một trong những cải tiến mang tính đột phá nhất trong lĩnh vực AI. Một trong nhiều bước liên quan đến quá trình đào tạo xe tự lái là phát hiện làn đường, đây là bước sơ bộ. Trong bài thực hành này, chúng ta sẽ tìm hiểu cách thực hiện phát hiện làn đường bằng thuật toán Canny."]},{"cell_type":"markdown","metadata":{"id":"HuGMqyOc6h-r"},"source":["# Mục tiêu học tập\n","\n","Sau khi hoàn thành bài thực hành này, học viên sẽ học được các kiến thức:\n","- Các kĩ thuật xử lí ảnh thời gian thực.\n","- Áp dụng Canny để nhận diện làn đường."]},{"cell_type":"markdown","metadata":{"id":"qGBsWUCH6kT_"},"source":["# Những kiến thức liên quan\n","\n","- Kĩ năng lập trình cơ bản với Python\n","- Sử dụng được các hàm cơ bản của OpenCV\n","- Thuật toán Canny."]},{"cell_type":"markdown","metadata":{"id":"q3jLmLfi6vzN"},"source":["# Hướng dẫn\n","\n","Dưới đây là hướng dẫn chi tiết các bước để bạn có thể lập trình và chạy được xe bám làn.\n"]},{"cell_type":"markdown","metadata":{"id":"YwiK8oA96roX"},"source":["# Bài toán\n","\n","**Mục tiêu**: Mô hình xe có thể chạy bám làn đường với tốc độ chậm.\n","\n","**Yêu cầu**: Xử lý nhận diện làn đường bằng thuật toán Canny."]},{"cell_type":"markdown","metadata":{"id":"L5_NBDAF6xx7"},"source":["## Thư viện\n","\n","Đầu tiên, để bắt đầu, ta cần nhập các thư viện cần thiết."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"AOim6Sv06Xjs"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import glob\n","import matplotlib.image as mpimage\n","import requests\n","import time\n","from urllib.request import urlopen\n","from queue import Queue\n","import threading"]},{"cell_type":"markdown","metadata":{"id":"R7Ux9HmD7ibN"},"source":["## Calibration\n","\n","Calibration trong xử lý ảnh là quá trình điều chỉnh các cảm biến và hệ thống quang học của máy ảnh để đảm bảo rằng ảnh được ghi lại chính xác phản ánh thực tế.\n","\n","Hàm 'CameraCalibration' sẽ có nhiệm vụ chỉnh **Độ méo ống kính** bằng cách sử dụng các ảnh của bàn cờ vua. Bàn cờ vua được sử dụng vì chúng có các góc dễ dàng nhận dạng bởi thuật toán.\n","\n","1. **Khởi tạo:**:\n","    - Khởi tạo các danh sách và mảng cần thiết.\n","\n","2. **Xử lý từng ảnh:**:\n","    - Sử dụng hàm 'cv2.findChessboardCorners' để tìm các góc bàn cờ trong ảnh.\n","\n","3. **Hiệu chuẩn camera:**\n","    - Sử dụng hàm 'cv2.calibrateCamera' của OpenCV để tính toán các tham số nội tại của camera (mtx, dist) dựa trên các danh sách 'objpoints' và 'imgpoints'.\n","\n","4. **Hàm 'undistort':**\n","    - Hàm này cho phép người dùng loại bỏ biến dạng thấu kính (distortion) từ ảnh bằng cách sử dụng các tham số nội tại được tính toán (mtx, dist) và hàm 'cv2.undistort' của OpenCV.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"umEeVMqF6Xju"},"outputs":[],"source":["class CameraCalibration():\n","    \"\"\" Class that calibrate camera using chessboard images \"\"\"\n","\n","    def __init__(self, image_dir, nx, ny):\n","        \"\"\" Init CameraCalibration.\n","\n","        Parameters:\n","            image_dir (str): path to folder contains chessboard images\n","            nx (int): width of chessboard (number of squares)\n","            ny (int): height of chessboard (number of squares)\n","        \"\"\"\n","        # Using glob to get a list of all image filenames in the specified directory\n","        fnames = glob.glob(\"{}/*\".format(image_dir))\n","\n","        objpoints = []  # List to store 3D points of chessboard corners\n","        imagepoints = []  # List to store 2D points of chessboard corners in the image\n","\n","        # Coordinates of chessboard's corners in 3D\n","        # Generating coordinates for 3D points for chessboard corners\n","        objp = np.zeros((nx*ny, 3), np.float32)\n","        # Filling the array with coordinates of the chessboard corners\n","        objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n","\n","        # Go through all chessboard images\n","        for f in fnames:\n","            # Loading image using matplotlib's imread function\n","            image = mpimage.imread(f)\n","\n","            # Using OpenCV's function to find chessboard corners\n","            ret, corners = cv2.findChessboardCorners(image, (nx, ny))\n","            # If corners are found\n","            if ret:\n","                # Append the corner coordinates to the list\n","                imagepoints.append(corners)\n","                # Append the 3D coordinates to the list\n","                objpoints.append(objp)\n","\n","        # Get shape of the last image processed\n","        shape = (image.shape[1], image.shape[0])\n","        ret, self.mtx, self.dist, _, _ = cv2.calibrateCamera(\n","            # Calibrating the camera using OpenCV's calibrateCamera function\n","            objpoints, imagepoints, shape, None, None)\n","\n","        # If calibration was unsuccessful\n","        if not ret:\n","            raise Exception(\"Unable to calibrate camera\")\n","\n","    # Undistort an image\n","    def undistort(self, image):\n","        \"\"\" Return undistort image.\n","\n","        Parameters:\n","            image (np.array): Input image\n","\n","        Returns:\n","            Image (np.array): Undistorted image\n","        \"\"\"\n","        # Undistort the grayscale image using OpenCV's undistort function\n","        return cv2.undistort(image, self.mtx, self.dist, None, self.mtx)"]},{"cell_type":"markdown","metadata":{},"source":["**Bài tập 1:** Hãy hoàn thành đoạn code sau bằng cách điền vào [...].\n","\n","Biến dang quang học là hiện tượng phổ biến khi chụp ảnh. Sự biến dạng xuyên tâm làm cho các đường thẳng có vẻ cong. Biến dạng xuyên tâm trở nên lớn hơn khi các điểm ở xa tâm ảnh hơn. \n","Ví dụ: một hình ảnh được bên dưới cho thấy hai cạnh của bàn cờ (đánh dấu bằng các đường màu đỏ). \n","\n","\n","<img src=\"Markdown Image\\Chessboard1.png\" alt=\"\" width=\"640\" height=\"360\">\n","\n","\n","Tuy nhiên, bạn có thể thấy đường viền của bàn cờ không phải là một đường thẳng và không khớp với đường màu đỏ.\n","\n","\n","Để giải quyết vấn đề này chúng ta cần Camera Calibration (Hiệu chuẩn máy ảnh)\n","\n","\n","<img src=\"Markdown Image\\Chessboard2.png\" alt=\"\" width=\"640\" height=\"360\">\n","\n","Dữ liệu đầu cho việc hiệu chỉnh camera là tập hợp các điểm trong thế giới thực 3D và tọa độ 2D tương ứng của các điểm này trong ảnh.\n","Trong bài lap này chúng ta sẽ xác định các điểm giao nhau trong hình ảnh bàn cờ\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Đường dẫn đến thư mục chứa các ảnh bàn cờ.\n","image_dir = r'[...]'\n","nx = [...]  # Số điểm giao nhau trong 1 hàng\n","ny = [...]  # Số điểm giao nhau trong 1 cột\n","\n","# Initialize camera calibration object\n","calibrator = CameraCalibration([...], [...], [...])\n","\n","# Kiểm tra kết quả\n","# Đường dẫn đến 1 ảnh bàn cờ\n","example_image = cv2.imread(r'[...]')\n","# Undistort the example image\n","undistorted_image = calibrator.undistort(example_image)\n","# Show the original and undistorted image (optional)\n","cv2.imshow(\"Original Image\", example_image)\n","cv2.imshow(\"Undistorted Image\", undistorted_image)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["image_dir = r'E:/Code/ACE/AI/LaneDetection/camera_cal'\n","nx = 9\n","ny = 6\n","\n","# Initialize camera calibration object\n","calibrator = CameraCalibration(image_dir, nx, ny)\n","\n","# Kiểm tra kết quả\n","# Đường dẫn đến 1 ảnh bàn cờ\n","example_image = cv2.imread(\n","    r'E:/Code/ACE\\AI/LaneDetection/Lap/Markdown Image/Chessboard.jpg')\n","# Undistort the example image\n","undistorted_image = calibrator.undistort(example_image)\n","# Show the original and undistorted image (optional)\n","cv2.imshow(\"Original Image\", example_image)\n","cv2.imshow(\"Undistorted Image\", undistorted_image)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"qfTHpigO9aih"},"source":["## Chuyển góc nhìn ảnh\n","\n","Lớp 'PerspectiveTransformation' dùng để chuyển đổi ảnh giữa góc nhìn phía trước và góc nhìn trên xuống (up to down).\n","\n","1. **Khởi tạo**:\n","    - Thiết lập các điểm nguồn và điểm đích cho phép biến đổi.\n","    - Điểm nguồn là bốn điểm trên ảnh gốc tượng trưng cho góc nhìn phía trước. - Điểm đích là bốn điểm tạo thành một hình chữ nhật xác định vùng nhìn trên xuống.\n","\n","2. **Hàm 'forward'**:\n","    - Thực hiện phép biến đổi để chuyển ảnh từ góc nhìn phía trước thành góc nhìn trên xuống.\n","\n","3. **Hàm 'backward'**:\n","    -  Thực hiện phép biến đổi ngược lại, chuyển ảnh từ góc nhìn trên xuống về góc nhìn phía trước."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"3mGJGt9t6Xjv"},"outputs":[],"source":["class PerspectiveTransformation:\n","    \"\"\" Transforming image between front view and top view \"\"\"\n","\n","    def __init__(self, src, dst):\n","        # Compute perspective transformation matrix\n","        self.M = cv2.getPerspectiveTransform(src, dst)\n","        # Compute inverse perspective transformation matrix\n","        self.M_inv = cv2.getPerspectiveTransform(dst, src)\n","\n","    # Convert image to bird-eye view\n","    def forward(self, image, image_size=(1280, 720), flags=cv2.INTER_LINEAR):\n","        \"\"\" Take a front view image and transform to top view\n","\n","        Parameters:\n","            image (np.array): A front view image\n","            image_size (tuple): Size of the image (width, height)\n","            flags : flag to use in cv2.warpPerspective()\n","\n","        Returns:\n","            Image (np.array): Top view image\n","        \"\"\"\n","        return cv2.warpPerspective(image, self.M, image_size, flags=flags)\n","\n","    # Restore image from bird-eye view to original perspective\n","    def backward(self, image, image_size=(1280, 720), flags=cv2.INTER_LINEAR):\n","        \"\"\" Take a top view image and transform it to front view\n","\n","        Parameters:\n","            image (np.array): A top view image\n","            image_size (tuple): Size of the image (width, height)\n","            flags (int): flag to use in cv2.warpPerspective()\n","\n","        Returns:\n","            Image (np.array): Front view image\n","        \"\"\"\n","        return cv2.warpPerspective(image, self.M_inv, image_size, flags=flags)"]},{"cell_type":"markdown","metadata":{},"source":["**Bài tập 2:** Hãy hoàn thành đoạn code sau bằng cách điền vào [...].\n","\n","Trong việc điều khiển xe tự hành, việc xác định làn đường là vô cùng quan trọng. \n","Để phát hiện được đường đi một cách dễ dàng và hiệu quả hơn, chúng ta có thể sử dụng phương pháp chuyển đổi góc nhìn giữa góc nhìn trước và góc nhìn từ trên xuống (bird's-eye view).\n","\n","<img src=\"Markdown Image\\Birds-eye_view.png\" alt=\"\" width=\"640\" height=\"200\">\n","                                            \n","Hàm forward của class PerspectiveTransformation sẽ chuyển các điểm gốc (src_points) sang các điểm đích (dst_points) để chuyển góc nhìn của ảnh. Các điểm là tọa độ của pixel trên ảnh đầu vào. \n","\n","<img src=\"Markdown Image\\xy_aris.png\" alt=\"\" width=\"300\" height=\"300\">\n","\n","Điểm top-left và bottom-left của src-point sẽ trùng với vạch kẻ đường khi lốp xe bên phải của bộ xe ACE-kit chạm vào vạch đường bên phải và tương tự với bên còn lại.\n","Vì hạn chế của phần cứng nên ta nên lấy 1/3 ảnh dưới (y = 450) để việc xác đinh đường đi (ỏ phần sau) có độ ổn định cao                                                                                                                       \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Đường dẫn đến 1 ảnh đường đi\n","example_image = cv2.imread(\"[...]\")\n","example_image = cv2.resize(example_image, (1280, 720))\n","\n","# Define source points for perspective transformation\n","src_points = np.float32([([...], [...]),      # top-left\n","                        ([...], [...]),       # bottom-left\n","                        ([...], [...]),     # bottom-right\n","                        ([...], [...])])     # top-right\n","\n","# Define destination points for perspective transformation\n","dst_points = np.float32([(100, 0),\n","                        (100, 720),\n","                        (1180, 720),\n","                        (1180, 0)])\n","\n","# Draw point in image\n","image = example_image\n","# Draw destination points (in blue)\n","for i, point in enumerate(src_points):\n","    cv2.circle(image, (int(point[0]), int(point[1])),\n","               5, (255, 0, 0), -1)  # Draw a filled circle\n","    cv2.putText(image, str(i+1), (int(point[0])-10, int(point[1])-10),\n","                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n","\n","# Draw destination points (in red)\n","for i, point in enumerate(dst_points):\n","    cv2.circle(image, (int(point[0]), int(point[1])),\n","               5, (0, 0, 255), -1)  # Draw a filled circle\n","    cv2.putText(image, str(i+1), (int(point[0])-10, int(point[1])-10),\n","                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n","cv2.imshow(\"Normal Image\", image)\n","\n","# Transform image to bird-eye view\n","transform = PerspectiveTransformation([...], [...])\n","transform_image = transform.forward([...])\n","\n","# Show the transform image\n","cv2.imshow(\"Transformed Image\", transform_image)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["# Đường dẫn đến 1 ảnh đường đi\n","example_image = cv2.imread(r'E:/Code/ACE/AI/LaneDetection/Lap/6.jpg')\n","example_image = cv2.resize(example_image, (1280, 720))\n","\n","# Define source points for perspective transformation\n","src_points = np.float32([(550, 450),      # top-left\n","                        (80, 720),       # bottom-left\n","                        (1200, 720),     # bottom-right\n","                        (730, 450)])     # top-right\n","\n","# Define destination points for perspective transformation\n","dst_points = np.float32([(100, 0),\n","                        (100, 720),\n","                        (1180, 720),\n","                        (1180, 0)])\n","\n","# Draw point in image\n","image = example_image.copy()\n","# Draw destination points (in blue)\n","for i, point in enumerate(src_points):\n","    cv2.circle(image, (int(point[0]), int(point[1])),\n","               5, (255, 0, 0), -1)  # Draw a filled circle\n","    cv2.putText(image, str(i+1), (int(point[0])-10, int(point[1])-10),\n","                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n","\n","# Draw destination points (in red)\n","for i, point in enumerate(dst_points):\n","    cv2.circle(image, (int(point[0]), int(point[1])),\n","               5, (0, 0, 255), -1)  # Draw a filled circle\n","    cv2.putText(image, str(i+1), (int(point[0])-10, int(point[1])-10),\n","                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n","cv2.imshow(\"Normal Image\", image)\n","\n","# Transform image to bird-eye view\n","transform = PerspectiveTransformation(src_points, dst_points)\n","transform_image = transform.forward(example_image)\n","\n","# Show the transform image\n","cv2.imshow(\"Transformed Image\", transform_image)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"kazWp1Xl-Q23"},"source":["## Thresholding\n","\n","Class 'Thresholding' thực hiện phân ngưỡng ảnh để tách ra các vạch kẻ làn đường trong ảnh. Hàm sử dụng hai phương pháp phân ngưỡng: phân ngưỡng tuyệt đối và phân ngưỡng tương đối.\n","    \n","H (Hue): biểu diễn loại màu sắc trong vòng tròn quang phổ với đơn vị đo là góc có giá trị thuộc khoảng  [0,179].\n","\n","S (Saturation): biểu diễn mức độ bão hòa màu với mức độ thuộc khoảng [0,255].\n","\n","V (hay B) (Value hay Bright): biểu diễn độ sáng của màu với dải giá trị thuộc khoảng [0,255].   \n","\n","\n","1. **Phân ngưỡng tuyệt đối**: 'threshold_abs()'\n","   - được sử dụng trên kênh H (Hue) của ảnh HLS để trích xuất vùng màu của vạch kẻ làn đường.\n","   - Giá trị tham số low và high là ngưỡng giá trị màu trong thang HUE.\n","      + 20, 30 là màu vàng\n","\n","2. **Phân ngưỡng tương đối**: 'threshold_rel()'\n","   - được sử dụng trên kênh V (Value) của ảnh HSV để trích xuất các vùng sáng tối của ảnh, thông qua mức độ tương phản.\n","\n","\n","Hàm thực hiện phân ngưỡng cho cả làn đường bên trái và làn đường bên phải, sau đó kết hợp kết quả phân ngưỡng của hai làn đường lại với nhau để tạo thành ảnh nhị phân cuối cùng, chỉ chứa các pixel thuộc vạch kẻ làn đường."]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["# Calculate relative thresholding\n","def threshold_rel(image, lo, hi):\n","    # Calculate the minimum pixel value in the image\n","    vmin = np.min(image)\n","    # Calculate the maximum pixel value in the image\n","    vmax = np.max(image)\n","\n","    # Compute the low threshold value based on the given percentage 'lo'\n","    vlo = vmin + (vmax - vmin) * lo\n","    # Compute the high threshold value based on the given percentage 'hi'\n","    vhi = vmin + (vmax - vmin) * hi\n","    # Apply the thresholding operation and convert to uint8 data type\n","    return np.uint8((image >= vlo) & (image <= vhi)) * 255\n","\n","\n","def threshold_abs(image, lo, hi):  # Function definition for absolute thresholding\n","    # Apply the thresholding operation and convert to uint8 data type\n","    return np.uint8((image >= lo) & (image <= hi)) * 255\n","\n","\n","class Thresholding:\n","    \"\"\" Extracting relevant pixels in an image \"\"\"\n","\n","    def __init__(self):  # Constructor method for the class (currently empty)\n","        pass\n","\n","    def forward(self, image):\n","        \"\"\" Take an image and extract all relavant pixels.\n","\n","        Parameters:\n","            image (np.array): Input image\n","\n","        Returns:\n","            binary (np.array): A binary image represent all positions of relavant pixels.\n","        \"\"\"\n","        # Convert the input image to HLS color space\n","        hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n","        # Convert the input image to HSV color space\n","        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n","        # Extract the H (hue) channel from the HLS image\n","        h_channel = hls[:, :, 0]\n","        # Extract the S (saturation) channel from the HLS image\n","        s_channel = hls[:, :, 2]\n","        # Extract the V (value) channel from the HSV image\n","        v_channel = hsv[:, :, 2]\n","\n","        # Check if left lane line is  yellow\n","        # left_lane = threshold_abs(h_channel, 20, 30)\n","\n","        # Get left lane line pixel\n","        left_lane = threshold_rel(v_channel, 0.7, 1.0)\n","\n","        # Get right lane line pixel\n","        right_lane = threshold_rel(v_channel, 0.7, 1.0)\n","\n","        # Combine the thresholded images for left and right lanes using logical OR\n","        result = left_lane | right_lane\n","\n","        return result  # Return the resulting binary image with lane markings"]},{"cell_type":"markdown","metadata":{},"source":["**Bài tập 3:** Hãy hoàn thành đoạn code sau bằng cách điền vào [...].                                  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Đường dẫn đến 1 ảnh đường đi\n","example_image = cv2.imread(r'[...]')\n","example_image = cv2.resize(example_image, (1280, 720))\n","\n","thresholding = Thresholding()\n","\n","image = example_image.copy()\n","undistort_image = calibrator.undistort([...])\n","bird_eye_image = transform.forward([...])\n","thresholding_image = thresholding.forward([...])\n","\n","\n","# Show the transform image\n","cv2.imshow(\"Thresholding Image\", [...])\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"cdUXyGXo6Xjw"},"outputs":[],"source":["# Đường dẫn đến 1 ảnh đường đi\n","example_image = cv2.imread(\n","    r'E:\\Code\\ACE\\AI\\LaneDetection\\Lap\\Test Image\\Lane_line.jpg')\n","example_image = cv2.resize(example_image, (1280, 720))\n","\n","\n","thresholding = Thresholding()\n","\n","image = example_image.copy()\n","undistort_image = calibrator.undistort(image)\n","bird_eye_image = transform.forward(undistort_image)\n","thresholding_image = thresholding.forward(bird_eye_image)\n","\n","\n","# Show the transform image\n","cv2.imshow(\"Normal Image\", example_image)\n","cv2.imshow(\"Transformed Image\", thresholding_image)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"EFo4h12D-lNC"},"source":["## Nhận diện làn đường\n","\n","Hàm này dùng để phát hiện vạch kẻ làn đường trong ảnh. Nó là một lớp có tên là 'LaneLines'.\n","\n","1. **Khởi tạo**:\n","    - Lớp tạo ra các biến để lưu trữ các thông tin về vạch kẻ làn đường và các thuộc tính của lớp.\n","\n","2. **Hàm 'hist()'**:\n","    - Tính toán histogram của nửa dưới của ảnh.\n","\n","3. **Hàm 'pixels_in_window()'**:\n","    - Trả về tất cả các điểm ảnh nằm trong một cửa sổ cụ thể.\n","\n","4. **Hàm 'extract_features()'**:\n","    - Trích xuất các đặc trưng từ ảnh nhị phân, lưu trữ kích thước cửa sổ trượt, các chỉ số của điểm ảnh khác 0 trong ảnh và lưu trữ tọa độ x, y của các điểm ảnh đó.\n","\n","5. **Hàm 'find_lane_pixels()'**:\n","    - Tìm các điểm ảnh thuộc vạch kẻ làn đường trong một ảnh nhị phân đã được biến dạng.\n","    - Trả về tọa độ x, y của các điểm ảnh vạch kẻ cho mỗi bên trái và phải, cùng với ảnh RGB được sử dụng để hiển thị kết quả sau này.\n","\n","6. **Hàm 'fit_poly()'**:\n","    - Tính toán đường cong cho các điểm ảnh vạch kẻ được phát hiện và vẽ lên ảnh.\n","\n","7. **Hàm 'plot()'**:\n","    - Thêm thông tin bổ sung vào ảnh đầu ra, bao gồm hướng di chuyển và độ cong của vạch kẻ làn đường.\n","\n","8. **Hàm 'measure_curvature()'**:\n","    - Đo độ cong của vạch kẻ làn đường và vị trí xe.\n","\n","9. **Hàm 'forward()'**:\n","    - Xử lý ảnh đầu vào và phát hiện vạch kẻ làn đường.\n","    - Trả về ảnh RGB với các điểm ảnh vạch kẻ được đánh dấu và các chi tiết khác."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aBgLb0W6Xjx"},"outputs":[],"source":["# Compute histogram of bottom half of the image\n","def hist(image):\n","    # Select bottom half of the image\n","    bottom_half = image[image.shape[0]//2:, :]\n","    # Compute histogram along the horizontal axis\n","    return np.sum(bottom_half, axis=0)\n","\n","\n","# Class for lane line detection\n","class LaneLines:\n","    \"\"\" Detected lane lines \"\"\"\n","\n","    def __init__(self):\n","        self.left_fit = None    # Coefficients of the left lane polynomial fit\n","        self.right_fit = None   # Coefficients of the right lane polynomial fit\n","        self.nonzero = None     # Indices of nonzero pixels in the image\n","        self.nonzerox = None    # X coordinates of nonzero pixels\n","        self.nonzeroy = None    # Y coordinates of nonzero pixels\n","        self.dir = []           # List to store directions of detected lanes\n","        self.msg = \"Straight\"   # Default message for lane direction\n","\n","        self.nwindows = 9   # Number of sliding windows for lane detection\n","        self.margin = 30    # Margin around the previous window to search for lane pixels\n","        self.minpix = 50    # Minimum number of pixels to recenter the window\n","\n","    # Method to compute pixel indices within a window\n","\n","    def pixels_in_window(self, center, margin, height):\n","        \"\"\" Return all pixel that in a specific window\n","\n","        Parameters:\n","            center (tuple): coordinate of the center of the window\n","            margin (int): half width of the window\n","            height (int): height of the window\n","\n","        Returns:\n","            pixelx (np.array): x coordinates of pixels that lie inside the window\n","            pixely (np.array): y coordinates of pixels that lie inside the window\n","        \"\"\"\n","        # Top-left corner of the window\n","        topleft = (center[0]-margin, center[1]-height//2)\n","        # Bottom-right corner of the window\n","        bottomright = (center[0]+margin, center[1]+height//2)\n","\n","        # Condition to select pixels within the window boundaries\n","        condx = (topleft[0] <= self.nonzerox) & (\n","            self.nonzerox <= bottomright[0])\n","        condy = (topleft[1] <= self.nonzeroy) & (\n","            self.nonzeroy <= bottomright[1])\n","        # Return selected pixel coordinates\n","        return self.nonzerox[condx & condy], self.nonzeroy[condx & condy]\n","\n","    # Method to extract features from the input image\n","    def extract_features(self, image):\n","        \"\"\" Extract features from a binary image\n","\n","        Parameters:\n","            image (np.array): A binary image\n","        \"\"\"\n","        self.image = image  # Store the input image\n","        # Compute the height of each sliding window\n","        self.window_height = int(image.shape[0]//self.nwindows)\n","\n","        # Compute indices of nonzero pixels in the image\n","        self.nonzero = image.nonzero()\n","        self.nonzerox = np.array(self.nonzero[1])\n","        self.nonzeroy = np.array(self.nonzero[0])\n","\n","    # Method to find lane pixels within sliding windows\n","    def find_lane_pixels(self, image):\n","        \"\"\"Find lane pixels from a binary warped image.\n","\n","        Parameters:\n","            image (np.array): A binary warped image\n","\n","        Returns:\n","            leftx (np.array): x coordinates of left lane pixels\n","            lefty (np.array): y coordinates of left lane pixels\n","            rightx (np.array): x coordinates of right lane pixels\n","            righty (np.array): y coordinates of right lane pixels\n","            out_image (np.array): A RGB image that use to display result later on.\n","        \"\"\"\n","        # Ensure input image is grayscale\n","        assert (len(image.shape) == 2)\n","        # Create an image to draw detected lane pixels\n","        out_image = np.dstack((image, image, image))\n","\n","        # Compute histogram of the bottom half of the image\n","        histogram = hist(image)\n","        # Compute midpoint of the histogram\n","        midpoint = histogram.shape[0]//2\n","        # Find the peak of the left half of the histogram\n","        leftx_base = np.argmax(histogram[:midpoint])\n","        # Find the peak of the right half of the histogram\n","        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n","\n","        # Initialize current x coordinate for left lane\n","        leftx_current = leftx_base\n","        # Initialize current x coordinate for right lane\n","        rightx_current = rightx_base\n","        # Initialize current y coordinate\n","        y_current = image.shape[0] + self.window_height//2\n","        # Initialize lists to store detected lane pixels\n","        leftx, lefty, rightx, righty = [], [], [], []\n","\n","        # Loop through each sliding window\n","        for _ in range(self.nwindows):\n","            # Move the window position upward\n","            y_current -= self.window_height\n","\n","            # Define center coordinates of the current sliding window\n","            center_left = (leftx_current, y_current)\n","            center_right = (rightx_current, y_current)\n","\n","            # Find lane pixels within the current sliding window\n","            good_left_x, good_left_y = self.pixels_in_window(\n","                center_left, self.margin, self.window_height)\n","            good_right_x, good_right_y = self.pixels_in_window(\n","                center_right, self.margin, self.window_height)\n","\n","            # Append detected lane pixels to the respective lists\n","            leftx.extend(good_left_x)\n","            lefty.extend(good_left_y)\n","            rightx.extend(good_right_x)\n","            righty.extend(good_right_y)\n","\n","            # Recenter the sliding window if enough pixels are found\n","            if len(good_left_x) > self.minpix:\n","                leftx_current = np.int32(np.mean(good_left_x))\n","            if len(good_right_x) > self.minpix:\n","                rightx_current = np.int32(np.mean(good_right_x))\n","\n","        # Return detected lane pixels and the image with visualization\n","        return leftx, lefty, rightx, righty, out_image\n","\n","    # Fit polynomial curves to the detected lane pixels\n","    def fit_poly(self, image):\n","        \"\"\"Find the lane line from an image and draw it.\n","\n","        Parameters:\n","            image (np.array): a binary warped image\n","\n","        Returns:\n","            out_image (np.array): a RGB image that have lane line drawn on that.\n","        \"\"\"\n","        # Find lane pixels''\n","        leftx, lefty, rightx, righty, out_image = self.find_lane_pixels(\n","            image)\n","        # Fit polynomial curves to the detected lane pixels\n","        if len(lefty) > 1500:\n","            self.left_fit = np.polyfit(lefty, leftx, 2)\n","        if len(righty) > 1500:\n","            self.right_fit = np.polyfit(righty, rightx, 2)\n","\n","        # Compute y coordinates for plotting the lane lines\n","        maxy = image.shape[0] - 1\n","        miny = image.shape[0] // 3\n","        if len(lefty):\n","            maxy = max(maxy, np.max(lefty))\n","            miny = min(miny, np.min(lefty))\n","        if len(righty):\n","            maxy = max(maxy, np.max(righty))\n","            miny = min(miny, np.min(righty))\n","        ploty = np.linspace(miny, maxy, image.shape[0])\n","\n","        # Compute x coordinates for plotting the lane lines\n","        left_fitx = self.left_fit[0]*ploty**2 + \\\n","            self.left_fit[1]*ploty + self.left_fit[2]\n","        right_fitx = self.right_fit[0]*ploty**2 + \\\n","            self.right_fit[1]*ploty + self.right_fit[2]\n","\n","        # Draw the lane lines on the output image\n","        for i, y in enumerate(ploty):\n","            l = int(left_fitx[i])\n","            r = int(right_fitx[i])\n","            y = int(y)\n","            cv2.line(out_image, (l, y), (r, y), (0, 255, 0))\n","\n","        # Measure curvature and return the image with lane lines drawn\n","        lR, rR, pos = self.measure_curvature()\n","        return out_image\n","\n","    # Method to plot additional information on the output image\n","    def plot(self, out_image):\n","        np.set_printoptions(precision=6, suppress=True)\n","        lR, rR, pos = self.measure_curvature()  # Measure curvature\n","\n","        # Determine driving direction based on lane curvature\n","        value = None\n","        if abs(self.left_fit[0]) > abs(self.right_fit[0]):\n","            value = self.left_fit[0]\n","        else:\n","            value = self.right_fit[0]\n","\n","        # Update driving direction history\n","        if abs(value) <= 0.00020:\n","            self.dir.append('F')  # Forward\n","        elif value < 0:\n","            self.dir.append('L')  # Left\n","        else:\n","            self.dir.append('R')  # Right\n","\n","        # Maintain a history of driving directions\n","        if len(self.dir) > 10:\n","            self.dir.pop(0)\n","\n","        # Determine the predominant driving direction\n","        direction = max(set(self.dir), key=self.dir.count)\n","\n","        # Display lane direction and curvature information on the output image\n","        curvature_msg = \"Curvature = {:.0f} m\".format(min(lR, rR))\n","        if direction == 'L':\n","            self.msg = \"Left\"\n","        if direction == 'R':\n","            self.msg = \"Right\"\n","        if direction == 'F':\n","            self.msg = \"Straight\"\n","\n","        cv2.putText(out_image, self.msg, org=(10, 240), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n","                    # Display lane direction\n","                    fontScale=1, color=(255, 255, 255), thickness=2)\n","        if direction in 'LR':\n","            cv2.putText(out_image, curvature_msg, org=(\n","                # Display curvature\n","                10, 280), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n","        cv2.putText(\n","            out_image,\n","            \"Vehicle is {:.2f} m away from center\".format(pos),\n","            org=(10, 310),\n","            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n","            fontScale=0.66,\n","            color=(255, 255, 255),\n","            thickness=2)  # Display distance from lane center\n","        return out_image  # Return the image with additional information\n","\n","    # Method to measure lane curvature and vehicle position\n","    def measure_curvature(self):\n","        ym = 30/720  # Meters per pixel in y dimension\n","        xm = 3.7/700  # Meters per pixel in x dimension\n","\n","        # Copy coefficients of polynomial fits\n","        left_fit = self.left_fit.copy()\n","        right_fit = self.right_fit.copy()\n","\n","        # Compute y coordinate for evaluating curvature\n","        y_eval = 700 * ym\n","\n","        # Compute curvature radius for left and right lanes\n","        left_curveR = (\n","            (1 + (2*left_fit[0] * y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n","        right_curveR = (\n","            (1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n","\n","        # Compute vehicle position relative to lane center\n","        xl = np.dot(self.left_fit, [700**2, 700, 1])\n","        xr = np.dot(self.right_fit, [700**2, 700, 1])\n","        pos = (1280//2 - (xl+xr)//2)*xm\n","\n","        # Return curvature radii and vehicle position\n","        return left_curveR, right_curveR, pos\n","\n","    # Process input image and detect lane lines\n","    def forward(self, image):\n","        \"\"\"Take a image and detect lane lines.\n","\n","        Parameters:\n","            image (np.array): An binary image containing relevant pixels\n","\n","        Returns:\n","            Image (np.array): An RGB image containing lane lines pixels and other details\n","        \"\"\"\n","        # Extract features from the input image\n","        self.extract_features(image)\n","        # Fit polynomial curves to detected lane pixels\n","        return self.fit_poly(image)"]},{"cell_type":"markdown","metadata":{"id":"L_pk1Bdj-eYI"},"source":["## Xây dựng model để nhận diện làn đường\n","\n","**Hàm 'FindLaneLines'** có chức năng xử lý ảnh đầu vào để tìm vạch lane trên đường.\n","\n","1. **Khởi tạo:**\n","    - Khởi tạo một đối tượng 'CameraCalibration' để loại bỏ biến dạng ảnh từ camera.\n","    - Khởi tạo các đối tượng khác để thực hiện ngưỡng ảnh (Thresholding), biến đổi phối cảnh (PerspectiveTransformation) và tìm vạch lane (LaneLines).\n","\n","2. **Xử lý ảnh 'forward':**\n","    - Nắn chỉnh ảnh đầu vào để loại bỏ biến dạng thấu kính (undistort) bằng 'CameraCalibration'.\n","    - Biến đổi phối cảnh ảnh để có góc nhìn từ trên xuống đường (perspective transform) bằng 'PerspectiveTransformation'.\n","    - Chuyển đổi ảnh đã biến đổi phối cảnh thành ảnh nhị phân để tách biệt vạch lane với phần còn lại (thresholding) bằng 'Thresholding'.\n","    - Tìm vạch lane trong ảnh nhị phân bằng 'LaneLines'.\n","    - Biến đổi phối cảnh ngược lại để đưa ảnh về phối cảnh ban đầu.\n","    - Trộn ảnh gốc với ảnh kết quả đã tìm thấy vạch lane để hiển thị kết quả.\n","\n","3. **Xử lý ảnh thời gian thực 'process_image_rt':**\n","    - Gọi hàm 'forward' để xử lý ảnh theo các bước trên.\n","\n","Nhìn chung, hàm 'FindLaneLines' sử dụng các chức năng xử lý ảnh khác nhau để tách vạch lane ra khỏi ảnh đường và hiển thị chúng lên ảnh gốc."]},{"cell_type":"markdown","metadata":{},"source":["**Bài tập 4:** Hãy hoàn thành đoạn code sau bằng cách điền vào [...].                                  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class FindLaneLines:\n","    def __init__(self):\n","        self.calibration = [...]\n","        self.thresholding = [...]\n","        self.transform = [...]\n","        self.lanelines = [...]\n","\n","    # Process the input image and find lane lines\n","    def forward(self, image):\n","        # Create a copy of the input image\n","        output_image = np.copy([...])\n","        # Undistort the input image using camera calibration\n","        undistort_image = self.calibration.undistort([...])\n","        # Apply perspective transformation to bird-eye view image\n","        bird_eye_image = self.transform.forward([...])\n","        # Apply thresholding to the transformed image to extract lane pixels\n","        threshold_image = self.thresholding.forward([...])\n","        # Detect lane lines in the thresholded image\n","        laneline_image = self.lanelines.forward([...])\n","        # Reverse the perspective transformation to obtain the original perspective\n","        laneline_image = self.transform.backward([...])\n","\n","        # Blend the processed image with the original image\n","        output_image = cv2.addWeighted(output_image, 1, laneline_image, 0.6, 0)\n","        # Plot additional information (lane direction, curvature, etc.) on the processed image\n","        output_image = self.lanelines.plot([...])\n","        # Return the final processed image\n","        return output_image\n","\n","    # Process the input image and find lane lines in real-time\n","    def process_image_rt(self, image):\n","        # Forward the input image to the 'forward' method to find lane lines\n","        output_image = self.forward([...])\n","        # Return the processed image\n","        return output_image"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["class FindLaneLines:\n","    def __init__(self):\n","        self.calibration = CameraCalibration('camera_cal', 9, 6)\n","        self.thresholding = Thresholding()\n","        self.transform = PerspectiveTransformation()\n","        self.lanelines = LaneLines()\n","\n","    # Process the input image and find lane lines\n","    def forward(self, image):\n","        # Create a copy of the input image\n","        output_image = np.copy(image)\n","        # Undistort the input image using camera calibration\n","        undistort_image = self.calibration.undistort(image)\n","        # Apply perspective transformation to bird-eye view image\n","        bird_eye_image = self.transform.forward(undistort_image)\n","        # Apply thresholding to the transformed image to extract lane pixels\n","        threshold_image = self.thresholding.forward(bird_eye_image)\n","        # Detect lane lines in the thresholded image\n","        laneline_image = self.lanelines.forward(threshold_image)\n","        # Reverse the perspective transformation to obtain the original perspective\n","        laneline_image = self.transform.backward(laneline_image)\n","\n","        # Blend the processed image with the original image\n","        output_image = cv2.addWeighted(output_image, 1, laneline_image, 0.6, 0)\n","        # Plot additional information (lane direction, curvature, etc.) on the processed image\n","        output_image = self.lanelines.plot(output_image)\n","        # Return the final processed image\n","        return output_image\n","\n","    # Process the input image and find lane lines in real-time\n","    def process_image_rt(self, image):\n","        # Forward the input image to the 'forward' method to find lane lines\n","        output_image = self.forward(image)\n","        # Return the processed image\n","        return output_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TItSGADQ6Xjy"},"outputs":[],"source":["class FindLaneLines:\n","    def __init__(self):\n","        self.calibration = CameraCalibration('camera_cal', 9, 6)\n","        self.thresholding = Thresholding()\n","        self.transform = PerspectiveTransformation()\n","        self.lanelines = LaneLines()\n","\n","    # Process the input image and find lane lines\n","    def forward(self, image):\n","        # Create a copy of the input image\n","        out_image = np.copy(image)\n","        # Undistort the input image using camera calibration\n","        image = self.calibration.undistort(image)\n","        # Apply perspective transformation to the undistorted image\n","        image = self.transform.forward(image)\n","        # Apply thresholding to the transformed image to extract lane pixels\n","        image = self.thresholding.forward(image)\n","        # Detect lane lines in the thresholded image\n","        image = self.lanelines.forward(image)\n","        # Reverse the perspective transformation to obtain the original perspective\n","        image = self.transform.backward(image)\n","\n","        # Blend the processed image with the original image\n","        out_image = cv2.addWeighted(out_image, 1, image, 0.6, 0)\n","        # Plot additional information (lane direction, curvature, etc.) on the processed image\n","        out_image = self.lanelines.plot(out_image)\n","        # Return the final processed image\n","        return out_image\n","\n","    # Process the input image and find lane lines in real-time\n","    def process_image_rt(self, image):\n","        # Forward the input image to the 'forward' method to find lane lines\n","        out_image = self.forward(image)\n","        # Return the processed image\n","        return out_image"]},{"cell_type":"markdown","metadata":{"id":"LNri3bRCAZ69"},"source":["## Khai báo các biến local\n","\n","Chúng ta cần khai báo các biến local để phục vụ cho quá trình lập trình. Trong đó sẽ bao gồm:\n","- 'find_lane_lines' là một object thuộc class 'FindLaneLines()'\n","- 'url_image' là đường link để lấy hình ảnh từ cam.\n","- 'url_cmd' là đường link để truyền lệnh đến xe.\n","- 'speed_cmd' là tốc độ của xe.\n","- 'msg_to_dir_cmd' là định nghĩa các lệnh sang dạng số.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iZJwIsxh6Xjz"},"outputs":[],"source":["find_lane_lines = FindLaneLines()\n","url_image = r'http://192.168.109.103/capture'\n","url_cmd = \"http://192.168.109.103:81/message\"\n","speed_cmd = 35\n","msg_to_dir_cmd = {\n","    \"Straight\": 1,\n","    \"Left\": 7,\n","    \"Right\": 5,\n","    \"Stop\": 9,\n","}\n","\n","queue_image = Queue()"]},{"cell_type":"markdown","metadata":{"id":"YXF0TmCXAc2J"},"source":["## Lấy dữ liệu hình ảnh\n","\n","Hàm 'get_image()' có nhiệm vụ lấy hình ảnh liên tục từ một URL, chuyển đổi và xử lý chúng, sau đó đặt vào hàng đợi để các phần khác của chương trình có thể sử dụng các hình ảnh này."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"REP3v9uE6Xj0"},"outputs":[],"source":["# Get image from server of the carkit\n","def get_image():\n","    while True:\n","        try:\n","            # Open the URL to fetch image\n","            image = urlopen(url_image, timeout=5)\n","            # Convert image data to NumPy array\n","            imagenp = np.asarray(bytearray(image.read()), dtype=\"uint8\")\n","            image = cv2.imdecode(imagenp, -1)  # Decode the image\n","            image = cv2.resize(image, (1280, 720))  # Resize the image\n","            queue_image.put(image)  # Put the image into the queue\n","            # Check if the queue size exceeds the maximum limit\n","            if queue_image.qsize() >= 3:\n","                _ = queue_image.get()  # Pop the oldest image\n","        except Exception as e:\n","            print(\"Error fetching image:\", e)\n","            time.sleep(1)  # Wait for 1 second before retrying"]},{"cell_type":"markdown","metadata":{"id":"Zy381n9cBKTZ"},"source":["# Test lấy dữ liệu hình ảnh\n","\n","Hàm 'display_image()' dùng để kiểm tra tính năng lấy ảnh từ bộ xe. Ảnh sẽ được lấy ra từ hàng đợi và hiển thị ra màn hình kèm với FPS."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"300AltHIA22c"},"outputs":[],"source":["# Test the getting image process of carkit\n","def display_image():\n","    prev_time = time.time()  # Record the previous time\n","    while True:\n","        try:\n","            image = queue_image.get()  # Get an image from the queue\n","            image = find_lane_lines.process_image_rt(\n","                image)  # Process the image in real-time\n","\n","            current_time = time.time()  # Record the current time\n","            fps = 1 / (current_time - prev_time)  # Calculate frames per second\n","            prev_time = current_time  # Update the previous time\n","\n","            cv2.putText(image, f\"FPS: {int(fps)}\", (10, 30),\n","                        # Add FPS text to the image\n","                        cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n","            cv2.imshow(\"Detected Image\", image)  # Display the image\n","\n","            if cv2.waitKey(1) & 0xFF == ord('q'):  # Check for 'q' key press to exit\n","                break\n","        except Exception as e:\n","            print(\"Error:\", e)  # Print any errors"]},{"cell_type":"markdown","metadata":{"id":"VVdRscRBA_tX"},"source":["## Nhận diện làn đường\n","\n","Hàm 'process_image()' được thiết kế liên tục xử lý hình ảnh từ hàng đợi, điều khiển phương tiện dựa trên kết quả xử lý và hiển thị hình ảnh đã xử lý cùng với FPS.\n","\n","Quá trình này sẽ được thực hiện trong một vòng lặp vô hạn:\n","- Lấy hình ảnh từ hàng đợi.\n","- Đưa qua 'find_lane_lines.process_image_rt(img)' để xử lý hình ảnh và tìm các làn đường.\n","- Sau đó lấy thông điệp điều khiển xe từ 'find_lane_lines.lanelines.msg'.\n","- Chuyển đổi thông điệp điều khiển thành mã lệnh và gửi yêu cầu POST đến 'url_cmd' để điều khiển phương tiện.\n","\n","Vòng lặp sẽ dừng lại khi ta nhấn phím 'q'.\n","\n","Chức năng của hàm này là liên tục xử lý hình ảnh từ hàng đợi, điều khiển phương tiện dựa trên kết quả xử lý và hiển thị hình ảnh đã xử lý cùng với FPS."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LRJhexPbA8ZP"},"outputs":[],"source":["# Process image to extract line and motion control\n","def process_image():\n","    prev_time = time.time()  # Record the previous time\n","    while True:\n","        try:\n","            image = queue_image.get()  # Get an image from the queue\n","            current_time = time.time()  # Record the current time\n","            fps = 1 / (current_time - prev_time)  # Calculate frames per second\n","            prev_time = current_time  # Update the previous time\n","            # Process the image in real-time\n","            image = find_lane_lines.process_image_rt(image)\n","            msg = find_lane_lines.lanelines.msg  # Get the lane direction message\n","        except Exception as e:\n","            print(\"Error processing image:\", e)  # Print errors\n","            cv2.putText(image, f\"Not found\", (150, 30),\n","                        # Add \"Not found\" text to the image\n","                        cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n","            msg = \"Stop\"  # Set message to \"Stop\"\n","\n","        # Get the command code corresponding to the message\n","        dir_cmd = msg_to_dir_cmd.get(msg, 9)\n","        data = {\"Cmd\": f\"{dir_cmd} {speed_cmd}\"}  # Construct the command data\n","        print(data)  # Print the command data\n","        # Send command to the vehicle\n","        response = requests.post(url_cmd, data=data)\n","        print(response.text)  # Print the response\n","\n","        cv2.putText(image, f\"FPS: {int(fps)}\", (10, 30),\n","                    # Add FPS text to the image\n","                    cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n","        cv2.imshow(\"Detected Image\", image)  # Display the image\n","\n","        if cv2.waitKey(1) & 0xFF == ord('q'):  # Check for 'q' key press to exit\n","            msg = \"Stop\"  # Set default message to \"Stop\"\n","            # Get the command code corresponding to the message\n","            dir_cmd = msg_to_dir_cmd.get(msg, 9)\n","            # Construct the command data\n","            data = {\"Cmd\": f\"{dir_cmd} {speed_cmd}\"}\n","            # Send command to the vehicle\n","            response = requests.post(url_cmd, data=data)\n","            break  # Exit the loop"]},{"cell_type":"markdown","metadata":{"id":"8iSRZip7Byt1"},"source":["**Bài tập 5:** Hãy hoàn thành đoạn code sau bằng cách điền vào [...].                                  \n","\n","Để tăng hiệu suất xử lí và giảm tải khối lượng công việc, chúng ta sẽ sử dụng kĩ thuật chạy đa luồng. Luồng một sẽ nhằm mục đích lấy hình ảnh từ server và lưu vào hàng đợi. Luồng hai sẽ xử lí ảnh từ hàng đợi và đưa lệnh cho xe.\n","- Luồng 1 lấy ảnh từ bộ ACE-kit\n","- Luồng 2 xử lý nhận diện làn đường "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create two threads\n","thread1 = threading.Thread(target=[...], name='Thread 1')\n","thread2 = threading.Thread(target=[...], name='Thread 2')\n","# Start the threads\n","thread1.start()\n","thread2.start()\n","# Wait for the threads to finish\n","thread1.join()\n","thread2.join()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ObMQO4z6Xj0"},"outputs":[],"source":["# Create two threads\n","thread1 = threading.Thread(target=get_image, name='Thread 1')\n","thread2 = threading.Thread(target=process_image, name='Thread 2')\n","# Start the threads\n","thread1.start()\n","thread2.start()\n","# Wait for the threads to finish\n","thread1.join()\n","thread2.join()\n","cv2.destroyAllWindows()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
